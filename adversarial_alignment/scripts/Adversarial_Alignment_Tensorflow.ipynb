{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24904,"status":"ok","timestamp":1684126527507,"user":{"displayName":"FENG Pinyuan","userId":"16238921250041619986"},"user_tz":240},"id":"Dfeo4w-HnmmT","outputId":"4237c440-4186-4965-b84e-17dae2b482ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import csv\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","import time\n","import gc\n","import numpy as np\n","from scipy.stats import spearmanr\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFLwvbEhnpe4"},"outputs":[],"source":["!cp '/content/drive/MyDrive/Research/Adversarial_Attacks_Model-VS-Human/datasets/clickme_test_1000.tfrecords' ./"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8894,"status":"ok","timestamp":1684126542693,"user":{"displayName":"FENG Pinyuan","userId":"16238921250041619986"},"user_tz":240},"id":"-E3PInADnphF","outputId":"84abfc1c-ae3a-44d5-b2b3-500db7d7ad95"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.8/656.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q harmonization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drSpUluCsl_E"},"outputs":[],"source":["from harmonization.models import (load_ViT_B16, load_ResNet50,\n","                                  load_VGG16, load_EfficientNetB0,\n","                                  load_tiny_ConvNeXT, load_tiny_MaxViT,\n","                                  load_LeViT_small,\n","                                  preprocess_input)\n","# model = load_ResNet50()\n","# model_name = \"resnet50v2_harmonized\"\n","\n","# model = load_VGG16()\n","# model_name = \"vgg16_harmonized\"\n","\n","# model = load_ViT_B16()\n","# model_name = \"vit_b16_harmonized\"\n","\n","# model = load_EfficientNetB0()\n","# model_name = \"efficientnet_b0_harmonized\"\n","\n","model = load_tiny_ConvNeXT()\n","model_name = \"convnext_tiny_harmonized\"\n","\n","# model = load_tiny_MaxViT()\n","# model_name = \"maxvit_tiny_harmonized\"\n","\n","# Bad Performance !!!\n","# model = load_LeViT_small()\n","# model_name = \"levit_small_harmonized\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xzptjx05oICa"},"outputs":[],"source":["class Dataset:\n","    def __init__(self, data_path):\n","        self.data_path = data_path\n","        \n","        self.AUTO = tf.data.AUTOTUNE\n","\n","        self._feature_description = {\n","            \"image\"       : tf.io.FixedLenFeature([], tf.string, default_value=''),\n","            \"heatmap\"     : tf.io.FixedLenFeature([], tf.string, default_value=''),\n","            \"label\"       : tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","        }\n","\n","    def parse_prototype(self, prototype, training=False):\n","        data    = tf.io.parse_single_example(prototype, self._feature_description)\n","\n","        image   = tf.io.decode_raw(data['image'], tf.float32)\n","        image   = tf.reshape(image, (224, 224, 3))\n","        image   = tf.cast(image, tf.float32)\n","\n","        heatmap = tf.io.decode_raw(data['heatmap'], tf.float32)\n","        heatmap = tf.reshape(heatmap, (224, 224, 1))\n","\n","        label   = tf.cast(data['label'], tf.int32)\n","        label   = tf.one_hot(label, 1_000)\n","\n","        return image, heatmap, label\n","\n","    def get_dataset(self, batch_size, training=False):\n","        deterministic_order = tf.data.Options()\n","        deterministic_order.experimental_deterministic = True\n","\n","        dataset = tf.data.TFRecordDataset([self.data_path], num_parallel_reads=self.AUTO)\n","        dataset = dataset.with_options(deterministic_order) \n","        \n","        dataset = dataset.map(self.parse_prototype, num_parallel_calls=self.AUTO)\n","        \n","        dataset = dataset.batch(batch_size, drop_remainder=True)\n","        dataset = dataset.prefetch(self.AUTO)\n","\n","        return dataset\n","        \n","datapath = \"/content/clickme_test_1000.tfrecords\"\n","data = Dataset(datapath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0_if3nyoH97"},"outputs":[],"source":["loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False,)\n","\n","# @tf.function\n","def grads_step(xt, model, labels):\n","    with tf.GradientTape() as tape:\n","        tape.watch(xt)\n","        outputs = model(xt)\n","        # print(outputs.shape, labels.shape)     \n","        cost = tf.reduce_sum(loss(outputs, labels)) # (1, 1000) one-hot vector\n","    grads = tape.gradient(cost, xt)\n","    return grads\n","\n","def copy(x):\n","  return tf.cast(np.array(x).copy(), tf.float32)\n","\n","class Attack:\n","    def __init__(self):\n","        pass\n","    \n","    def l2(self, x):\n","        norm = tf.reduce_sum(tf.square(x), (1,2,3)) # batch_size, H, W, C\n","        norm = tf.sqrt(norm + 1e-4)\n","        return norm[:,None,None,None] # batch_size, 1, 1, 1\n","\n","    def l2_pgd_attack(self, model, images, labels, eps, alpha=10/255, iters=5):   \n","        x0 = tf.cast(copy(images), tf.float32)\n","        labels = tf.cast(labels, tf.float32)[None, :] # (1, 1000)\n","        xt = copy(x0)   \n","\n","        for i in range(iters) :        \n","            # print(xt.shape, labels.shape)\n","            grads = grads_step(xt, model, labels)\n","            x_next = xt + grads / self.l2(grads) * alpha\n","            \n","            # project the current point on the l2(x0, epsilon) ball :)\n","            delta = x_next - x0\n","            sigma = self.l2(delta) # norm\n","            x_next = x_next + (delta / sigma) * eps\n","            \n","            # ready for the next step\n","            xt = x_next\n","\n","        return xt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-mKCYJyoIAS"},"outputs":[],"source":["def execute_attack(model, img, target, eps, alpha):\n","    # Setup an attack\n","    attack_obj = Attack()\n","    perturbed_img = attack_obj.l2_pgd_attack(model, img, target, eps=eps, alpha=0.5, iters=3)\n","\n","    # Re-classify the perturbed image\n","    outputs = model(perturbed_img)\n","    pred = tf.argmax(outputs, -1)\n","    \n","    return perturbed_img, pred\n","\n","def write_csv_all(record, path):\n","    header = ['model', 'img', 'label', 'pred', 'eps', 'l2', 'linf', 'spearman']\n","    file_exists = os.path.isfile(path)\n","\n","    with open(path, mode='a+', newline='') as csv_file:\n","        writer = csv.writer(csv_file)\n","        if not file_exists:\n","            writer.writerow(header)\n","        writer.writerow(record)\n","\n","def write_csv_avg(record, path):\n","    header = [\n","        'model', 'num_correct', \n","        'avg_eps', 'std_eps', \n","        'avg_l2', 'std_l2', \n","        'avg_linf', 'std_linf', \n","        'avg_spearman', 'std_spearman']\n","\n","    file_exists = os.path.isfile(path)\n","    with open(path, mode='a+', newline='') as csv_file:\n","        writer = csv.writer(csv_file)\n","        if not file_exists:\n","            writer.writerow(header)\n","        writer.writerow(record)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYGL9Adt1vlI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684132587037,"user_tz":240,"elapsed":5957418,"user":{"displayName":"FENG Pinyuan","userId":"16238921250041619986"}},"outputId":"becf7240-53a5-46ab-8dfd-6af5623aa3e7"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["Folder already exists: /content/drive/MyDrive/Research/Adversarial_Attacks_Model-VS-Human/results/L2PGD_0.5_3_harmonized/\n","Searching optimal epsilon for image: 1000 | 1000 convnext_tiny_harmonized_5 \n"]}],"source":["# from tensorflow.keras.models import load_model\n","# model_name = \"convnext_tiny_harmonized_5\"\n","# pretrained = \"/content/drive/MyDrive/Research/Adversarial_Attacks_Model-VS-Human/Harmonizer zoo/models/\"\n","# model = load_model(pretrained + model_name + \".h5\")\n","\n","# Define paths\n","case = \"L2PGD_0.5_3_harmonized\"\n","folder_path = '/content/drive/MyDrive/Research/Adversarial_Attacks_Model-VS-Human/results/' + case + '/'\n","results_path_avg = folder_path + case + '.csv'\n","results_path_all = folder_path + model_name + '.csv'\n","\n","if not os.path.exists(folder_path):\n","    os.makedirs(folder_path)\n","    print(f\"Created folder: {folder_path}\")\n","else:\n","    print(f\"Folder already exists: {folder_path}\")\n","\n","\n","l2_list, linf_list = [], []\n","opt_epsilons = []\n","spearman_scores = []\n","total_cnt, init_correct, aa_correct = 0, 0, 0\n","\n","for imgs, hmps, labels in data.get_dataset(2 , False): # image, heatmap, label\n","    imgs = tf.cast(imgs, tf.float32)\n","    hmps = tf.cast(hmps, tf.float32)\n","    imgs = preprocess_input(imgs)\n","    labels = tf.cast(labels, tf.float32)\n","\n","    for img, hmp, label in zip(imgs, hmps, labels):\n","        # Add a batch dimension\n","        img = img[None, :, :, :] \n","        hmp = hmp[None, :, :, :]\n","        target = tf.argmax(label[:, None]) # tf.Tensor([343], shape=(1,), dtype=int64)\n","\n","        # Predict\n","        output = model(img)\n","        init_pred = tf.argmax(output, axis=-1) # tf.Tensor([343], shape=(1,), dtype=int64)\n","        # print(label.shape, target, init_pred)\n","\n","        # If the initial prediction is wrong, just move to the next image\n","        total_cnt += 1\n","        print(\"\\rSearching optimal epsilon for image: %s | %s %s\" % (str(total_cnt), str(1000), model_name), end=\" \")\n","        if init_pred.numpy()[0] != target.numpy()[0]:\n","            continue\n","        init_correct += 1\n","        \n","        # Apply first attack\n","        initial_eps = 10\n","        perturbed_img, perturbed_pred = execute_attack(model=model, img=img, target=label, eps=initial_eps, alpha=0.5)\n","\n","        if perturbed_pred.numpy()[0] == target.numpy()[0]: # Assume 10 is the min eps that fools the model\n","            optimal_eps = initial_eps\n","        else:\n","            # key: eps; val: perturbed_img\n","            info = {} # Only store one key-val pair\n","            key = None\n","\n","            initial_eps = 1\n","            perturbed_img, perturbed_pred = execute_attack(model=model, img=img, target=label, eps=initial_eps, alpha=0.5)\n","\n","            key = initial_eps\n","            info[key] = (perturbed_img, perturbed_pred)\n","\n","            if perturbed_pred.numpy()[0] == target.numpy()[0]: \n","                l, r = 1, 10 # search eps between 1 and 10\n","                threshold = 0.1 \n","            else:\n","                l, r = 0.001, 1 # search eps between 0.001 and 1\n","                threshold = 0.01\n","            \n","            while r - l >= threshold:\n","                eps = l + (r - l) / 2\n","                # print(eps)\n","                perturbed_img, perturbed_pred = execute_attack(model=model, img=img, target=label, eps=eps, alpha=0.5)\n","                if perturbed_pred.numpy()[0] == target.numpy()[0]: \n","                    l = eps\n","                else:\n","                    r = eps\n","                    if r != key:\n","                        del info[key]\n","                        key = r\n","                        info[key] = (perturbed_img, perturbed_pred)\n","\n","            optimal_eps = r\n","            if r in info:\n","                perturbed_img, perturbed_pred = info[r]\n","            else:\n","                perturbed_img, perturbed_pred = execute_attack(model=model, img=img, target=label, eps=optimal_eps, alpha=0.5)\n","\n","        opt_epsilons.append(optimal_eps)\n","        # print(optimal_eps)\n","\n","        # Store l2, linf\n","        l2, linf = tf.norm(perturbed_img - img, ord=2).numpy(), tf.norm(perturbed_img - img, ord=np.inf).numpy()\n","        l2_list.append(l2)\n","        linf_list.append(linf)\n","\n","        # Spearman correlation\n","        mask = np.abs(np.mean(perturbed_img.numpy() - img.numpy(), axis=-1, keepdims=True)) # (1, 1, 224, 224)\n","        spearman_score, _ = spearmanr(mask.flatten(), hmp.numpy().flatten())\n","        spearman_scores.append(spearman_score)\n","\n","        # Save the data into \n","        row_data = [\n","            model_name, str(total_cnt-1), str(target.numpy()[0]), str(perturbed_pred.numpy()[0]), \n","            str(round(optimal_eps, 6)), str(l2), str(linf), str(spearman_score)\n","        ]\n","        # print(row_data)\n","        write_csv_all(row_data, results_path_all)\n","        \n","print(\"\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DMNq0Sd1xRX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684132587038,"user_tz":240,"elapsed":19,"user":{"displayName":"FENG Pinyuan","userId":"16238921250041619986"}},"outputId":"f4f6c6a1-12d2-409e-b9e6-638e3b703a33"},"outputs":[{"output_type":"stream","name":"stdout","text":["['convnext_tiny_harmonized_5', '889', '6.418002847300338', '3.632960596041218', '19.988203', '10.723778', '1.6975623', '1.1887592', '0.4428087849804497', '0.1776509614698785']\n"]}],"source":["# Save data\n","row_data = [\n","    model_name, str(init_correct), \n","    str(np.mean(opt_epsilons)), str(np.std(opt_epsilons)),\n","    str(np.mean(l2_list)), str(np.std(l2_list)),\n","    str(np.mean(linf_list)), str(np.std(linf_list)),\n","    str(np.mean(spearman_scores)), str(np.std(spearman_scores)),\n","]\n","print(row_data)\n","write_csv_avg(row_data, results_path_avg)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}